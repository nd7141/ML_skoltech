{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(1000, 10, n_redundant=3, n_informative=5, n_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical tests\n",
    "\n",
    "**`SelectKBest`** transforms the data based on relationship between columns and y variable.\n",
    "\n",
    "It takes a function for statistical test `score_func` and the number of features to keep `k`. \n",
    "Score function varies, but the general principle is to get as input `X` and `y`, and return `scores` for each column. \n",
    "For classification task there are 3 default functions: \n",
    "* **chi2** applies Chi-Squared test for each column and class. Importantly, accepts only non-negative features, suited for categorical data such as booleans and frequencies. Not used with continious data. \n",
    "* **f_classif** Computes ANOVA F-value test. Default. \n",
    "* **mutual_info_classif** Estimate mutual information for a discrete target variable.The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "For regression, you have also `f_regression`, `mutual_info_regression`.\n",
    "\n",
    "The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared: [(13, 11.132318964498543), (14, 10.283135830918578), (0, 9.5806654381196967), (17, 9.0684314014131129)]\n",
      "Anova: [(0, 76.310572532677071), (13, 70.887794689803201), (18, 59.28976658477373), (14, 58.061243403984086)]\n",
      "Mutual Info: [(16, 0.16046842301424835), (0, 0.1545718791073214), (18, 0.14041175607996426), (10, 0.13197219841729257)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Xtr = scaler.fit_transform(X)\n",
    "\n",
    "# Using chi-squared test\n",
    "selector = SelectKBest(score_func=chi2)\n",
    "fit = selector.fit(Xtr, y)\n",
    "print 'Chi-Squared:', sorted(enumerate(fit.scores_), key=lambda (ix, x): x, reverse=True)[:4]\n",
    "\n",
    "# Using Anova F-test\n",
    "selector = SelectKBest(score_func=f_classif)\n",
    "fit = selector.fit(Xtr, y)\n",
    "print 'Anova:', sorted(enumerate(fit.scores_), key=lambda (ix, x): x, reverse=True)[:4]\n",
    "\n",
    "# Using mutual info criteria\n",
    "selector = SelectKBest(score_func=mutual_info_classif)\n",
    "fit = selector.fit(Xtr, y)\n",
    "print 'Mutual Info:', sorted(enumerate(fit.scores_), key=lambda (ix, x): x, reverse=True)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive feature elimination\n",
    "\n",
    "For `RFE` a model trained on a full set of features, then eliminate features with the least absolute values, until necessary number of features is kept. `RFECV` can determine a number of informative features beased on cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE number of features: 4\n",
      "RFE: [(0, 1), (3, 1), (4, 1), (9, 1), (7, 2), (2, 3), (5, 4), (1, 5), (8, 6), (6, 7)]\n",
      "Optimal number of features 5\n",
      "RFECV: [(0, 1), (3, 1), (4, 1), (7, 1), (9, 1), (2, 2), (5, 3), (1, 4), (8, 5), (6, 6)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(lr, n_features_to_select=4)\n",
    "\n",
    "fit = rfe.fit(X, y)\n",
    "print 'RFE number of features:', fit.n_features_\n",
    "print 'RFE:', sorted(enumerate(fit.ranking_), key = lambda (ix, x): x)\n",
    "\n",
    "rfecv = RFECV(lr)\n",
    "fit = rfecv.fit(X, y)\n",
    "print 'Optimal number of features', fit.n_features_\n",
    "print 'RFECV:', sorted(enumerate(fit.ranking_), key = lambda (ix, x): x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1-norm based reduction\n",
    "\n",
    "L1-norm can reduce the number of feature by assigning zero weights. Importantly, with SVMs and logistic-regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000L, 9L) (1000L, 8L)\n",
      "(1000L, 9L) (1000L, 5L)\n",
      "[[-0.4941  0.      0.      0.      0.1193  0.      0.      0.0644  0.    ]\n",
      " [ 0.1625 -0.1297  0.0361  0.      0.     -0.0087 -0.0192  0.      0.    ]\n",
      " [ 0.1187  0.1428  0.     -0.0448  0.      0.      0.     -0.1788  0.    ]]\n",
      "\n",
      "[[-0.8032  0.      0.      0.      0.1137  0.      0.0236  0.1805  0.    ]\n",
      " [ 0.1846 -0.2059  0.      0.      0.      0.     -0.0673  0.      0.    ]\n",
      " [ 0.1748  0.2322  0.      0.      0.      0.      0.     -0.227   0.    ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X, y = make_classification(1000, 9, n_redundant=3, n_informative=5, n_classes=3)\n",
    "\n",
    "svm = LinearSVC(C=0.01, penalty='l1', dual=False).fit(X, y)\n",
    "model = SelectFromModel(svm, prefit=True)\n",
    "Xnew = model.transform(X)\n",
    "print X.shape, Xnew.shape\n",
    "\n",
    "sgd = SGDClassifier(alpha=0.1, penalty='l1').fit(X, y)\n",
    "model = SelectFromModel(sgd, prefit=True)\n",
    "Xtr = model.transform(X)\n",
    "print X.shape, Xtr.shape\n",
    "\n",
    "print svm.coef_\n",
    "print \n",
    "print sgd.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-based reduction\n",
    "\n",
    "Tree based methods outputs feature importances based on heuristic. It is sometimes called \"gini importance\" or \"mean decrease impurity\" and is defined as the total decrease in node impurity (weighted by the probability of reaching that node (which is approximated by the proportion of samples reaching that node)) averaged over all trees of the ensemble. Reference: Breiman, Friedman, \"Classification and regression trees\", 1984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 [ 0.055   0.0536  0.0484  0.0268  0.0278  0.0724  0.0622  0.0186  0.0506\n",
      "  0.0287  0.0716  0.0186  0.0404  0.0784  0.0439  0.0508  0.0832  0.065\n",
      "  0.0549  0.0491]\n",
      "(1000L, 20L) (1000L, 11L)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = make_classification(1000, 20, n_redundant=10, n_informative=5, n_classes=5)\n",
    "\n",
    "rf = RandomForestClassifier().fit(X, y)\n",
    "print np.mean(rf.feature_importances_), rf.feature_importances_\n",
    "\n",
    "model = SelectFromModel(rf, prefit=True)\n",
    "Xtr = model.transform(X)\n",
    "print X.shape, Xtr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 16 (0.083215)\n",
      "2. feature 13 (0.078395)\n",
      "3. feature 5 (0.072412)\n",
      "4. feature 10 (0.071594)\n",
      "5. feature 17 (0.065026)\n",
      "6. feature 6 (0.062241)\n",
      "7. feature 0 (0.054957)\n",
      "8. feature 18 (0.054894)\n",
      "9. feature 1 (0.053565)\n",
      "10. feature 15 (0.050794)\n",
      "11. feature 8 (0.050568)\n",
      "12. feature 19 (0.049138)\n",
      "13. feature 2 (0.048430)\n",
      "14. feature 14 (0.043882)\n",
      "15. feature 12 (0.040427)\n",
      "16. feature 9 (0.028708)\n",
      "17. feature 4 (0.027810)\n",
      "18. feature 3 (0.026777)\n",
      "19. feature 11 (0.018585)\n",
      "20. feature 7 (0.018581)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd811dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
